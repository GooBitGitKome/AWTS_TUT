{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQCS7ae27iQm"
      },
      "source": [
        "## API Keyの取得\n",
        "以下のリンクからAPI Keyを取得してください。\n",
        "- 手順\n",
        "1. リンクをクリック\n",
        "2. API Keyを取得するためのページが表示されたら、右のメニューから「Get API Key」を選択\n",
        "3. メニューの左側に「APIキーを取得」というページが表示されるので、そのページの「APIキーを作成」ボタンをクリック\n",
        "4. API Keyが作成され、取得できます！\n",
        "\n",
        "[Get Gemini API Key](https://aistudio.google.com/app/apikey)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XkXdF83ZlZU"
      },
      "source": [
        "※以下から6行のコード実行のための手順に移ります"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaJphe4qr0NT"
      },
      "source": [
        "## パッケージをインストール\n",
        "「llama-index-llms-gemini」と「llama-index-embeddings-gemini」をpipでインストール。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "WJVPoynqsOwc"
      },
      "outputs": [],
      "source": [
        "!pip -q install llama-index==0.10.14\n",
        "!pip -q install llama-index-llms-gemini llama-index-embeddings-gemini\n",
        "!pip -q install llama-index-llms-openai llama-index-embeddings-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvNu-f1rtVNk"
      },
      "source": [
        "## 環境変数の準備\n",
        "左のカギアイコンから「新しいシークレットを追加」を選択し、名前を「GOOGLE_API_KEY」、値を「取得したAPI Key」に設定。その後以下のコードを実行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8mp95Haspd8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "# GoogleのGeminiを使用する方はこちら（APIキーと呼ばれる、サービスを利用するための鍵を取る必要があります）\n",
        "#os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "# OpenAIのChatGPTを使用する方はこちら（APIキーと呼ばれる、サービスを利用するための鍵を取る必要があります）\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJ1YZe4It_0u"
      },
      "source": [
        "## LLMと埋め込みモデルの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8k4Pc-Pah7J"
      },
      "source": [
        "## Google Geminiのかたはこちら"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTV2rQh9uJ9z"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.gemini import GeminiEmbedding\n",
        "\n",
        "# LLMの準備\n",
        "Settings.llm = Gemini(\n",
        "    model_name=\"models/gemini-pro\",\n",
        ")\n",
        "\n",
        "# 埋め込みモデルの準備\n",
        "Settings.embed_model = GeminiEmbedding(\n",
        "    model_name=\"models/embedding-001\",  # 日本語に弱いが今回はこのモデル（サイトで紹介されていたモデル）を使用します\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwxSjYOKal5w"
      },
      "source": [
        "## OpenAI ChatGPTのかたはこちら"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxGVcLRPatcl"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "# LLMの準備\n",
        "Settings.llm = OpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    # model=\"gpt-4-turbo\", # 最新モデルはこちら\n",
        "    temperature=0\n",
        "    )\n",
        "\n",
        "# 埋め込みモデルの準備\n",
        "Settings.embed_model = OpenAIEmbedding(\n",
        "    model=\"text-embedding-3-large\",  # 日本語に弱いが今回はこのモデル（サイトで紹介されていたモデル）を使用します\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3D3YIdJvLgU"
      },
      "source": [
        "## Colabにdataディレクトリを作成し、ドキュメントを追加\n",
        "左のフォルダアイコンでファイルの一覧を表示し、右クリック「新しいフォルダ」でdataフォルダを作成し、フォルダ内にドキュメントを追加します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf3QvmrtvtJp"
      },
      "source": [
        "## 6行のコードを実行\n",
        "先生から提供して頂いたコードを実行します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6XgwpXtvrlP",
        "outputId": "7d73bcb4-213d-48af-cd3c-0f169a568183"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "桃太郎は程教授、米田アシスタント、愉快な仲間たちを連れて旅をしました。\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "\n",
        "response_1 = query_engine.query(\"桃太郎は何を連れて旅をしましたか？\") #ここに追加したドキュメントに対しての質問を追加\n",
        "#response_2 = query_engine.query(\"\")\n",
        "\n",
        "print(response_1)\n",
        "#print(response_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE5R7F9aignW"
      },
      "source": [
        "## 参考サイト\n",
        "リンクをクリックするとリダイレクトの警告文がでますが、表示されたリンクをクリックしてサイトにアクセスしてください。\n",
        "\n",
        "[LlamaIndexのGemini統合を試す](https://note.com/npaka/n/n68bd11eac933)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
